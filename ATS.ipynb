{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
      ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Docx file\n",
    "from docx import Document\n",
    "\n",
    "def load_docx(file_path):\n",
    "    try:\n",
    "        return Document(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading document: {e}\")\n",
    "        return None\n",
    "\n",
    "doc = load_docx('C:\\\\Users\\\\panda\\\\Documents\\\\Resume.docx')\n",
    "if not doc:\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 25 resumes across 7 job categories\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_resumes(data_path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    # Check if the path exists\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"The path {data_path} does not exist\")\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if not os.path.isdir(data_path):\n",
    "        raise NotADirectoryError(f\"{data_path} is not a directory\")\n",
    "    \n",
    "    for role in os.listdir(data_path):  # Loop over folders (job roles)\n",
    "        role_path = os.path.join(data_path, role)\n",
    "        \n",
    "        # Skip if not a directory\n",
    "        if not os.path.isdir(role_path):\n",
    "            continue\n",
    "            \n",
    "        for file in os.listdir(role_path):  # Loop over files inside each folder\n",
    "            file_path = os.path.join(role_path, file)\n",
    "            \n",
    "            # Skip if not a file\n",
    "            if not os.path.isfile(file_path):\n",
    "                continue\n",
    "                \n",
    "            # Skip non-text files (optional - adjust extensions as needed)\n",
    "            if not file.endswith(('.txt', '.pdf', '.docx', '.doc')):\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    text = f.read()\n",
    "                    texts.append(text)    # Store the resume text\n",
    "                    labels.append(role)   # Store the folder name as label\n",
    "            except UnicodeDecodeError:\n",
    "                # Try with a different encoding if utf-8 fails\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='latin-1') as f:\n",
    "                        text = f.read()\n",
    "                        texts.append(text)\n",
    "                        labels.append(role)\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not read file {file_path}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "    \n",
    "    if not texts:\n",
    "        print(\"Warning: No resume files were loaded\")\n",
    "        \n",
    "    return pd.DataFrame({'resume': texts, 'label': labels})\n",
    "\n",
    "# Call the function\n",
    "try:\n",
    "    df = load_resumes('E:\\\\Academic\\\\NLP\\\\Resumes')\n",
    "    print(f\"Successfully loaded {len(df)} resumes across {df['label'].nunique()} job categories\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load resumes: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\panda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....</td>\n",
       "      <td>Software engineer</td>\n",
       "      <td>pk ûp content_types xml ënã0 e hücä jü² 5í ç q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....</td>\n",
       "      <td>Software engineer</td>\n",
       "      <td>pk ûp content_types xml ënã0 e hücä jü² 5í ç q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....</td>\n",
       "      <td>Software engineer</td>\n",
       "      <td>pk ûp content_types xml ënã0 e hücä jü² 5í ç q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....</td>\n",
       "      <td>Software engineer</td>\n",
       "      <td>pk ûp content_types xml ënã0 e hücä jü² 5í ç q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>pk ûp content_types xml ënã0 e hücä jü² 5í ç q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>pk ûp content_types xml ënã0 e hücä jü² 5í ç q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>pk ûp content_types xml ënã0 e hücä jü² 5í ç q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000d-e\u0001\u0000\u0000\u0005\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>pk e content_types xml ënã0 e hücä jü² 5í ç q ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....</td>\n",
       "      <td>Marketing Manager</td>\n",
       "      <td>pk ûp content_types xml ënã0 e hücä jü² 5í ç q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....</td>\n",
       "      <td>Marketing Manager</td>\n",
       "      <td>pk ûp content_types xml ënã0 e hücä jü² 5í ç q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              resume              label  \\\n",
       "0  PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....  Software engineer   \n",
       "1  PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....  Software engineer   \n",
       "2  PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....  Software engineer   \n",
       "3  PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....  Software engineer   \n",
       "4  PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....       Data Analyst   \n",
       "5  PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....       Data Analyst   \n",
       "6  PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....       Data Analyst   \n",
       "7  PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000d-e\u0001\u0000\u0000\u0005\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....       Data Analyst   \n",
       "8  PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....  Marketing Manager   \n",
       "9  PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000\u001f#\u0004ûp\u0001\u0000\u0000\"\u0006\u0000\u0000\u0013\u0000\b\u0002[Content_Types]....  Marketing Manager   \n",
       "\n",
       "                                             cleaned  \n",
       "0  pk ûp content_types xml ënã0 e hücä jü² 5í ç q...  \n",
       "1  pk ûp content_types xml ënã0 e hücä jü² 5í ç q...  \n",
       "2  pk ûp content_types xml ënã0 e hücä jü² 5í ç q...  \n",
       "3  pk ûp content_types xml ënã0 e hücä jü² 5í ç q...  \n",
       "4  pk ûp content_types xml ënã0 e hücä jü² 5í ç q...  \n",
       "5  pk ûp content_types xml ënã0 e hücä jü² 5í ç q...  \n",
       "6  pk ûp content_types xml ënã0 e hücä jü² 5í ç q...  \n",
       "7  pk e content_types xml ënã0 e hücä jü² 5í ç q ...  \n",
       "8  pk ûp content_types xml ënã0 e hücä jü² 5í ç q...  \n",
       "9  pk ûp content_types xml ënã0 e hücä jü² 5í ç q...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'\\W+', ' ', text)           # Remove special characters\n",
    "    text = text.lower()                        # Lowercase\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "df['cleaned'] = df['resume'].apply(preprocess)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['03ïã' '0a²' '0bv' '0ª8s' '0º' '0þaé6' '0þtc' '14éæ' '1i' '1iö' '1xöpâ'\n",
      " '1ää' '1ì' '1ím' '1õöjh' '2r' '2î' '2ù' '2ü' '3bg¾' '3sngáw' '3yçé3cö'\n",
      " '3²àèx2üô1r' '3á' '3ãäh' '3ù' '4eçù' '4iúãúiïæq' '4ndõb' '4onb' '4¾ýñ'\n",
      " '4ßþù' '4ãn' '4ë' '4ü' '50' '5kc5y' '5q' '5ì' '5í' '5ðº' '5òhòk' '6hy'\n",
      " '6kkx' '6ng' '6ye4e' '6ê' '6ï' '6ó' '6þµ' '7jun' '7v' '7z' '7õ'\n",
      " '7õkpúllá' '8g' '8áòqsl' '8æôq¹' '8é' '8õ' '9fý0' '9àé' '9òm' '9ý' '_mµ'\n",
      " '_rels' '_y' '_²' '_áo' '_ó' '_ôx' '_öj' '_ù' 'a1' 'aa' 'acf' 'aj' 'am1'\n",
      " 'aolëµj' 'ap' 'app' 'as¹' 'aª' 'a½' 'aß' 'aåïzaí' 'aç½' 'aè' 'aë' 'aí'\n",
      " 'að½' 'aðäº' 'aó' 'aôðözsw' 'aü' 'b0z' 'bc' 'bjtçö' 'buwêþö' 'bys' 'b¼'\n",
      " 'bà' 'bã' 'bå' 'bç' 'bçr' 'bé¾' 'bê' 'bíð' 'bò' 'bòþ' 'bùq' 'bú' 'c2û'\n",
      " 'c3' 'cb' 'ci' 'content_types' 'core' 'cs' 'custom' 'cy' 'cz' 'cìü¾bã³'\n",
      " 'cí' 'cðû' 'có' 'da' 'dc' 'djcî' 'dk' 'docprops' 'document' 'dsrcý' 'du'\n",
      " 'du¾têoj¾k' 'dw' 'dx' 'dyos' 'd²âe' 'd³' 'dèmdý' 'dê' 'dí' 'dî' 'dð'\n",
      " 'dðó' 'dñ' 'dö' 'döå' 'dù' 'dý' 'e_' 'ea' 'ef' 'ei' 'ej' 'ek' 'em' 'eo'\n",
      " 'ey' 'e¾' 'eèó' 'eéd³¾' 'eì' 'eí' 'eï' 'eù' 'eûâ' 'eþ' 'f0' 'f3' 'f4'\n",
      " 'f5' 'f6çð' 'fc' 'fe' 'fhïblñ1' 'fký' 'fmêûøèdâù' 'fonttable' 'fq' 'fr'\n",
      " 'fuà' 'fx' 'få' 'fæüv' 'fê' 'fñ' 'fñí¼' 'g7' 'gh' 'go' 'gu' 'gvî' 'gë'\n",
      " 'gñxß' 'gò' 'gù' 'h5zqyäà' 'hb' 'hp' 'hq' 'hu¾têgj¾k' 'hv' 'hwnmñv'\n",
      " 'hxqî' 'hyè' 'h¹íis' 'h¹íá¹' 'hâ' 'hç' 'hèf' 'hê' 'hïgãcç' 'hô' 'hú' 'hû'\n",
      " 'hücä' 'i3' 'i4' 'i7' 'ij' 'il' 'injý' 'ipãrv' 'i²' 'i³' 'iàéib' 'iæîö'\n",
      " 'iç' 'iè' 'ié' 'iî' 'ið' 'iñýúµ0' 'iùë' 'iú' 'jbîðè' 'jh' 'jkhõµ' 'jwg'\n",
      " 'j³' 'jì' 'jî' 'jü²' 'k5' 'k5dàr' 'k5dð' 'kb' 'khkb' 'ks' 'kw' 'kwg' 'k²'\n",
      " 'k½' 'kà' 'kï' 'ký' 'l0' 'l3' 'l4¼½' 'l6' 'l9' 'lbùcóxg' 'lg' 'lt' 'ltü'\n",
      " 'lu' 'lzi0ó' 'l³' 'lß' 'lâåj' 'lä' 'lç' 'lé' 'lô' 'lþ' 'm_' 'mb' 'mc'\n",
      " 'mk' 'mo' 'mq' 'mr' 'ms' 'mucµ' 'mvx' 'mx' 'mz' 'mzt' 'mª' 'mà' 'må' 'mð'\n",
      " 'mðý' 'mñ' 'mò' 'möî8' 'mû' 'nf²ã' 'numbering' 'nz' 'nªqõ' 'n½' 'nßk'\n",
      " 'ní' 'nó' 'nô' 'nø' 'ný' 'nÿ' 'o0þf' 'o7üð' 'odq' 'op' 'ow' 'owf' 'ox'\n",
      " 'oª' 'oáâ' 'oã' 'oç' 'oì' 'oíx' 'oú0' 'oûaó½' 'p7' 'pa' 'pb' 'pk' 'ps'\n",
      " 'pt' 'p¼' 'pá' 'pã' 'pëfmj' 'pî' 'pòãvýj' 'pô' 'pö' 'púªò' 'pý' 'pþtc'\n",
      " 'qdg' 'qn' 'qo' 'qu' 'queå' 'qw' 'q¾' 'qå' 'që' 'qí' 'qî' 'qðb' 'qù' 'qú'\n",
      " 'qûø' 'rels' 'relspk' 'rf' 'rjùýz' 'rm' 'rmí1á¹àî' 'rt' 'ru' 'rv' 'rvî'\n",
      " 'rx' 'rxþâüù' 'râõ' 'ræ' 'rè' 'rënã0' 'rûü' 'settings' 'styles' 'sº'\n",
      " 'sàßïø' 'sâx' 'sã' 'sîdxáôój' 'sú' 'sü' 't4' 'tc' 'tccbcçóªú' 'td' 'th'\n",
      " 'theme' 'theme1' 'thï' 'tl' 'tnã' 'tq' 'tx' 't²9bxà' 'tã' 'tãª' 'tã²'\n",
      " 'tï' 'tù' 'tû' 'u_' 'ua' 'ub' 'uc' 'ue' 'ueà1' 'uo' 'uq' 'ur' 'ut' 'uµí'\n",
      " 'u¼' 'u½f' 'uû' 'vexª' 'vg' 'vgo3iîìhr' 'vh' 'vhø' 'vn' 'vpò' 'vr' 'vw'\n",
      " 'v³0¹' 'vº' 'vç4p' 'vðè' 'vò' 'vú½úc0' 'w0' 'websettings' 'wh' 'word'\n",
      " 'wpà' 'wq' 'ww' 'wéçxeyß' 'wë7t' 'wìà' 'wó' 'wóe' 'wûnû8' 'wü' 'x8' 'xe'\n",
      " 'xg' 'xml' 'xmlpk' 'xmlì' 'xmlìyk' 'xmlü' 'xq' 'xr' 'xuø' 'xy' 'xª' 'xâ'\n",
      " 'xåèi' 'xêî' 'xø' 'xþ' 'y0' 'ye' 'yg' 'yk' 'yq' 'yu' 'yz' 'yª' 'y²' 'y¹7'\n",
      " 'yè' 'yî' 'yó' 'yô' 'yþç' 'zhý' 'zj' 'zk' 'zofè' 'zq' 'zrr' 'z¾' 'zê'\n",
      " 'zî' 'zøä' 'zþ' 'zþç' 'ªqõr' 'ªqùr' 'ªs' 'ªñâ' 'ªý' '²e¾hó' '²uoz' '²¾'\n",
      " '²àzø' '²êel³íudæªê' '²ì¹i' '²ð_k' '²ò' '³j' '³¾' '³å' '³ì' '³úí' '³þìu'\n",
      " 'µ5ù' 'µq' 'µw' 'µâw' 'µã' 'µä' 'µê' 'µëýaéë' 'µòv' 'µô' 'µôf5' 'µôk5'\n",
      " 'µöt' '¹0' '¹å' '¹ål' '¹ëzíèa' 'º6' 'ºg' 'ºå' 'ºê' 'ºî' 'ºû' '¼4' '¼_'\n",
      " '¼j' '¼qôä' '¼ôò' '¼þ¾ã81' '½1' '½o' '½rk' '½â' '½å' '¾2übj' '¾4º' '¾o'\n",
      " '¾wæõ¼vþ' '¾ªþºªºº4sáâý' '¾òui' 'ß3' 'ßi0¾é' 'ßmü' 'ßªý' 'ßß' 'ßã' 'ßë'\n",
      " 'àe5' 'ài6' 'àq' 'àu' 'àvõ' 'ày' 'àµ' 'à¹yxü' 'àåä' 'àæ' 'àç' 'àë' 'àì'\n",
      " 'àòø' 'àô' 'àøs' 'àû' 'àük' 'àþ' 'á_' 'áa' 'ác' 'áe' 'áfôª' 'áj' 'ájã0'\n",
      " 'ák' 'ál' 'ámß' 'án' 'áns' 'áªw' 'áß' 'áã' 'áì8' 'áî' 'áó' 'áõõ' 'áþld'\n",
      " 'â4' 'â8' 'âbl' 'âk' 'âk5' 'âl' 'âld½lh' 'âmv5' 'âr' 'âu' 'âª' 'âã' 'âä'\n",
      " 'âæ' 'âîiìkr¼' 'âù' 'âúdãb' 'âû0' 'âþ²' 'ã9' 'ãa' 'ãc' 'ãcòé' 'ãi' 'ãl'\n",
      " 'ão5' 'ãp7' 'ãp9éä' 'ãr' 'ãª' 'ãã' 'ãð' 'ãõ' 'ãùä' 'ä96ã' 'äl' 'ätê' 'äß'\n",
      " 'äâ' 'äé' 'äü' 'äþî' 'å4' 'åe' 'åg5' 'åi' 'ål' 'åm5' 'åy' 'åz' 'åº' 'åã'\n",
      " 'åç' 'åè' 'åì' 'åôwþéx2á' 'åöá' 'åùazën' 'åû' 'åýs' 'æd' 'æe' 'æek'\n",
      " 'æekmtã²' 'æf' 'æh' 'æjð' 'æq' 'æuk' 'æuknªqõr' 'æx' 'æy' 'æyé' 'æë' 'æí'\n",
      " 'æî' 'æòè' 'æöfýê' 'æþ' 'ç3ó' 'ç4xwá²' 'çd' 'çe' 'çl' 'çmi' 'çn' 'çs'\n",
      " 'çããµ' 'çè' 'çë' 'çì' 'çó' 'çù' 'çûëoþ' 'çý' 'èeâ' 'èg' 'ègìzä' 'èn' 'èo'\n",
      " 'èx' 'èà' 'èé' 'èê' 'èñuv¹' 'èñzââ' 'èý' 'é4' 'é9x' 'é_' 'éagëòó' 'éb'\n",
      " 'éhj' 'ékt' 'ém' 'éoáý' 'éâ' 'éçøa' 'éì' 'éü' 'ê9' 'êk' 'êmìc' 'êp83'\n",
      " 'êr' 'êt' 'êv' 'êå' 'êë' 'êö' 'ëb' 'ëc' 'ëe' 'ëjã0' 'ëm' 'ën' 'ënã0'\n",
      " 'ënã6' 'ëp' 'ëu' 'ëv' 'ëw' 'ëà²' 'ëèq' 'ëõ' 'ëû' 'ëûõêà' 'ëÿ' 'ì8ìû' 'ìb'\n",
      " 'ìm' 'ìq' 'ìv' 'ì½' 'ìç' 'ìê' 'ìòb' 'ìòmë' 'ìô' 'ìú' 'í1' 'í5' 'ía'\n",
      " 'íacðxëó' 'íjã0' 'íqb' 'ís' 'ítswf' 'ítä' 'íx' 'íy' 'íz' 'íà' 'íâ' 'íã'\n",
      " 'íì' 'íõ9mô' 'íõî' 'íöü' 'íû' 'íü' 'îf' 'îqô' 'î²' 'î¾c' 'îâòúj' 'îã'\n",
      " 'îí' 'îî' 'îïæuvãú' 'îö' 'îù' 'îû' 'ï8' 'ïrt' 'ïræ' 'ïy' 'ïßüi' 'ïà' 'ïã'\n",
      " 'ïãn' 'ïòøh' 'ïôc' 'ïúá³' 'ïü' 'ïþb' 'ð2' 'ð8' 'ðaþñãývzhe' 'ðb' 'ðe'\n",
      " 'ðf' 'ðnï' 'ðz' 'ðzs' 'ð³' 'ð¼ñêz' 'ðð' 'ðñ' 'ðóåð7_îµj¾á' 'ðú'\n",
      " 'ðú¼ù¹ávª' 'ðû' 'ðþ' 'ñ8' 'ñb' 'ñoú' 'ñp' 'ñr' 'ñwb' 'ñz' 'ñ½qúá' 'ñ¾'\n",
      " 'ñà' 'ñæ' 'ñé' 'ñëà¾' 'ññ' 'ñú' 'ñú1' 'ò_' 'òav' 'òcå' 'òk' 'òm' 'òraiy'\n",
      " 'òzwb' 'ò¹k' 'òå' 'òêå' 'òñ' 'òø' 'òý' 'òýçdbîp' 'óg' 'óhòj' 'ój' 'óm'\n",
      " 'óq' 'ór' 'ó½5' 'ó½ñõd' 'óãoß' 'óé' 'óê' 'óïó' 'óýnâ' 'óþ' 'ô9' 'ô_' 'ôc'\n",
      " 'ôd' 'ôg' 'ôj5' 'ôu' 'ôw' 'ôx' 'ôµ' 'ô¾ê' 'ôåw' 'ôéw' 'ôí' 'ôîn' 'ôõ'\n",
      " 'ôû' 'ôûëç' 'õe' 'õhü' 'õt' 'õzó' 'õä' 'õå' 'õê' 'õë' 'õì' 'õó' 'õõsm'\n",
      " 'õõxcws' 'õùóa½' 'õûò' 'õý' 'õþbu' 'ö8' 'öi' 'ölsxþ' 'öt' 'öw' 'öx'\n",
      " 'ö³ðçóòf' 'öºõàk' 'öçcrÿ' 'öïî' 'öø' 'öù' 'ød' 'øe' 'øjº' 'øl' 'øy' 'øæ'\n",
      " 'øé' 'øê' 'øí' 'øðò' 'øó' 'øø' 'ù0' 'ù7' 'ùc' 'ùd' 'ùi' 'ùp' 'ùq' 'ùz'\n",
      " 'ùß' 'ùà' 'ùá' 'ùê' 'ùí' 'ùó' 'ùô' 'ùöoæøú' 'ùúô' 'ú0' 'úaë' 'úc' 'úp'\n",
      " 'úq' 'úqa' 'ús' 'úuc' 'úu¹ö' 'úã' 'úé' 'úòbýä' 'úû' 'ûk' 'ûp' 'ûrû8' 'ût'\n",
      " 'û¼x' 'ûñ' 'ûñí' 'ûø' 'ûøj' 'ü0' 'ü_ð' 'üa' 'üdéµ' 'üe' 'üe2²' 'ül' 'üp'\n",
      " 'üq' 'üæe' 'üê' 'üð' 'üù_ê' 'ý5' 'ýb' 'ýcõc' 'ýdrfî½g' 'ýgi' 'ýn' 'ýt'\n",
      " 'ýzõàçô' 'ýçî' 'ýüä' 'þ1' 'þe6x' 'þs' 'þsë' 'þw' 'þz½î' 'þå' 'þúho' 'þû'\n",
      " 'þý' 'þýç' 'ÿáðó' 'ÿêãé' 'ÿþ' 'ÿÿ']\n",
      "[[ 1  1  1 ...  1  2 13]\n",
      " [ 1  1  1 ...  1  1 13]\n",
      " [ 1  1  1 ...  1  1 13]\n",
      " ...\n",
      " [ 1  1  1 ...  1  1 12]\n",
      " [ 1  1  1 ...  1  0 12]\n",
      " [ 1  1  1 ...  1  1 12]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer(max_features=1000)\n",
    "BOW_matrix = v.fit_transform(df['cleaned'])\n",
    "print(v.get_feature_names_out())  \n",
    "print(BOW_matrix.toarray())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['03ïã' '0a²' '0bv' '0ª8s' '0º' '0þaé6' '0þtc' '14éæ' '1i' '1iö' '1xöpâ'\n",
      " '1ää' '1ì' '1ím' '1õöjh' '2r' '2î' '2ù' '2ü' '3bg¾' '3sngáw' '3yçé3cö'\n",
      " '3²àèx2üô1r' '3á' '3ãäh' '3ù' '4eçù' '4iúãúiïæq' '4ndõb' '4onb' '4¾ýñ'\n",
      " '4ßþù' '4ãn' '4ë' '4ü' '50' '5kc5y' '5q' '5ì' '5í' '5ðº' '5òhòk' '6hy'\n",
      " '6kkx' '6ng' '6ye4e' '6ê' '6ï' '6ó' '6þµ' '7jun' '7v' '7z' '7õ'\n",
      " '7õkpúllá' '8g' '8áòqsl' '8æôq¹' '8é' '8õ' '9fý0' '9àé' '9òm' '9ý' '_mµ'\n",
      " '_rels' '_y' '_²' '_áo' '_ó' '_ôx' '_öj' '_ù' 'a1' 'aa' 'acf' 'aj' 'am1'\n",
      " 'aolëµj' 'ap' 'app' 'as¹' 'aª' 'a½' 'aß' 'aåïzaí' 'aç½' 'aè' 'aë' 'aí'\n",
      " 'að½' 'aðäº' 'aó' 'aôðözsw' 'aü' 'b0z' 'bc' 'bjtçö' 'buwêþö' 'bys' 'b¼'\n",
      " 'bà' 'bã' 'bå' 'bç' 'bçr' 'bé¾' 'bê' 'bíð' 'bò' 'bòþ' 'bùq' 'bú' 'c2û'\n",
      " 'c3' 'cb' 'ci' 'content_types' 'core' 'cs' 'custom' 'cy' 'cz' 'cìü¾bã³'\n",
      " 'cí' 'cðû' 'có' 'da' 'dc' 'djcî' 'dk' 'docprops' 'document' 'dsrcý' 'du'\n",
      " 'du¾têoj¾k' 'dw' 'dx' 'dyos' 'd²âe' 'd³' 'dèmdý' 'dê' 'dí' 'dî' 'dð'\n",
      " 'dðó' 'dñ' 'dö' 'döå' 'dù' 'dý' 'e_' 'ea' 'ef' 'ei' 'ej' 'ek' 'em' 'eo'\n",
      " 'ey' 'e¾' 'eèó' 'eéd³¾' 'eì' 'eí' 'eï' 'eù' 'eûâ' 'eþ' 'f0' 'f3' 'f4'\n",
      " 'f5' 'f6çð' 'fc' 'fe' 'fhïblñ1' 'fký' 'fmêûøèdâù' 'fonttable' 'fq' 'fr'\n",
      " 'fuà' 'fx' 'få' 'fæüv' 'fê' 'fñ' 'fñí¼' 'g7' 'gh' 'go' 'gu' 'gvî' 'gë'\n",
      " 'gñxß' 'gò' 'gù' 'h5zqyäà' 'hb' 'hp' 'hq' 'hu¾têgj¾k' 'hv' 'hwnmñv'\n",
      " 'hxqî' 'hyè' 'h¹íis' 'h¹íá¹' 'hâ' 'hç' 'hèf' 'hê' 'hïgãcç' 'hô' 'hú' 'hû'\n",
      " 'hücä' 'i3' 'i4' 'i7' 'ij' 'il' 'injý' 'ipãrv' 'i²' 'i³' 'iàéib' 'iæîö'\n",
      " 'iç' 'iè' 'ié' 'iî' 'ið' 'iñýúµ0' 'iùë' 'iú' 'jbîðè' 'jh' 'jkhõµ' 'jwg'\n",
      " 'j³' 'jì' 'jî' 'jü²' 'k5' 'k5dàr' 'k5dð' 'kb' 'khkb' 'ks' 'kw' 'kwg' 'k²'\n",
      " 'k½' 'kà' 'kï' 'ký' 'l0' 'l3' 'l4¼½' 'l6' 'l9' 'lbùcóxg' 'lg' 'lt' 'ltü'\n",
      " 'lu' 'lzi0ó' 'l³' 'lß' 'lâåj' 'lä' 'lç' 'lé' 'lô' 'lþ' 'm_' 'mb' 'mc'\n",
      " 'mk' 'mo' 'mq' 'mr' 'ms' 'mucµ' 'mvx' 'mx' 'mz' 'mzt' 'mª' 'mà' 'må' 'mð'\n",
      " 'mðý' 'mñ' 'mò' 'möî8' 'mû' 'nf²ã' 'numbering' 'nz' 'nªqõ' 'n½' 'nßk'\n",
      " 'ní' 'nó' 'nô' 'nø' 'ný' 'nÿ' 'o0þf' 'o7üð' 'odq' 'op' 'ow' 'owf' 'ox'\n",
      " 'oª' 'oáâ' 'oã' 'oç' 'oì' 'oíx' 'oú0' 'oûaó½' 'p7' 'pa' 'pb' 'pk' 'ps'\n",
      " 'pt' 'p¼' 'pá' 'pã' 'pëfmj' 'pî' 'pòãvýj' 'pô' 'pö' 'púªò' 'pý' 'pþtc'\n",
      " 'qdg' 'qn' 'qo' 'qu' 'queå' 'qw' 'q¾' 'qå' 'që' 'qí' 'qî' 'qðb' 'qù' 'qú'\n",
      " 'qûø' 'rels' 'relspk' 'rf' 'rjùýz' 'rm' 'rmí1á¹àî' 'rt' 'ru' 'rv' 'rvî'\n",
      " 'rx' 'rxþâüù' 'râõ' 'ræ' 'rè' 'rënã0' 'rûü' 'settings' 'styles' 'sº'\n",
      " 'sàßïø' 'sâx' 'sã' 'sîdxáôój' 'sú' 'sü' 't4' 'tc' 'tccbcçóªú' 'td' 'th'\n",
      " 'theme' 'theme1' 'thï' 'tl' 'tnã' 'tq' 'tx' 't²9bxà' 'tã' 'tãª' 'tã²'\n",
      " 'tï' 'tù' 'tû' 'u_' 'ua' 'ub' 'uc' 'ue' 'ueà1' 'uo' 'uq' 'ur' 'ut' 'uµí'\n",
      " 'u¼' 'u½f' 'uû' 'vexª' 'vg' 'vgo3iîìhr' 'vh' 'vhø' 'vn' 'vpò' 'vr' 'vw'\n",
      " 'v³0¹' 'vº' 'vç4p' 'vðè' 'vò' 'vú½úc0' 'w0' 'websettings' 'wh' 'word'\n",
      " 'wpà' 'wq' 'ww' 'wéçxeyß' 'wë7t' 'wìà' 'wó' 'wóe' 'wûnû8' 'wü' 'x8' 'xe'\n",
      " 'xg' 'xml' 'xmlpk' 'xmlì' 'xmlìyk' 'xmlü' 'xq' 'xr' 'xuø' 'xy' 'xª' 'xâ'\n",
      " 'xåèi' 'xêî' 'xø' 'xþ' 'y0' 'ye' 'yg' 'yk' 'yq' 'yu' 'yz' 'yª' 'y²' 'y¹7'\n",
      " 'yè' 'yî' 'yó' 'yô' 'yþç' 'zhý' 'zj' 'zk' 'zofè' 'zq' 'zrr' 'z¾' 'zê'\n",
      " 'zî' 'zøä' 'zþ' 'zþç' 'ªqõr' 'ªqùr' 'ªs' 'ªñâ' 'ªý' '²e¾hó' '²uoz' '²¾'\n",
      " '²àzø' '²êel³íudæªê' '²ì¹i' '²ð_k' '²ò' '³j' '³¾' '³å' '³ì' '³úí' '³þìu'\n",
      " 'µ5ù' 'µq' 'µw' 'µâw' 'µã' 'µä' 'µê' 'µëýaéë' 'µòv' 'µô' 'µôf5' 'µôk5'\n",
      " 'µöt' '¹0' '¹å' '¹ål' '¹ëzíèa' 'º6' 'ºg' 'ºå' 'ºê' 'ºî' 'ºû' '¼4' '¼_'\n",
      " '¼j' '¼qôä' '¼ôò' '¼þ¾ã81' '½1' '½o' '½rk' '½â' '½å' '¾2übj' '¾4º' '¾o'\n",
      " '¾wæõ¼vþ' '¾ªþºªºº4sáâý' '¾òui' 'ß3' 'ßi0¾é' 'ßmü' 'ßªý' 'ßß' 'ßã' 'ßë'\n",
      " 'àe5' 'ài6' 'àq' 'àu' 'àvõ' 'ày' 'àµ' 'à¹yxü' 'àåä' 'àæ' 'àç' 'àë' 'àì'\n",
      " 'àòø' 'àô' 'àøs' 'àû' 'àük' 'àþ' 'á_' 'áa' 'ác' 'áe' 'áfôª' 'áj' 'ájã0'\n",
      " 'ák' 'ál' 'ámß' 'án' 'áns' 'áªw' 'áß' 'áã' 'áì8' 'áî' 'áó' 'áõõ' 'áþld'\n",
      " 'â4' 'â8' 'âbl' 'âk' 'âk5' 'âl' 'âld½lh' 'âmv5' 'âr' 'âu' 'âª' 'âã' 'âä'\n",
      " 'âæ' 'âîiìkr¼' 'âù' 'âúdãb' 'âû0' 'âþ²' 'ã9' 'ãa' 'ãc' 'ãcòé' 'ãi' 'ãl'\n",
      " 'ão5' 'ãp7' 'ãp9éä' 'ãr' 'ãª' 'ãã' 'ãð' 'ãõ' 'ãùä' 'ä96ã' 'äl' 'ätê' 'äß'\n",
      " 'äâ' 'äé' 'äü' 'äþî' 'å4' 'åe' 'åg5' 'åi' 'ål' 'åm5' 'åy' 'åz' 'åº' 'åã'\n",
      " 'åç' 'åè' 'åì' 'åôwþéx2á' 'åöá' 'åùazën' 'åû' 'åýs' 'æd' 'æe' 'æek'\n",
      " 'æekmtã²' 'æf' 'æh' 'æjð' 'æq' 'æuk' 'æuknªqõr' 'æx' 'æy' 'æyé' 'æë' 'æí'\n",
      " 'æî' 'æòè' 'æöfýê' 'æþ' 'ç3ó' 'ç4xwá²' 'çd' 'çe' 'çl' 'çmi' 'çn' 'çs'\n",
      " 'çããµ' 'çè' 'çë' 'çì' 'çó' 'çù' 'çûëoþ' 'çý' 'èeâ' 'èg' 'ègìzä' 'èn' 'èo'\n",
      " 'èx' 'èà' 'èé' 'èê' 'èñuv¹' 'èñzââ' 'èý' 'é4' 'é9x' 'é_' 'éagëòó' 'éb'\n",
      " 'éhj' 'ékt' 'ém' 'éoáý' 'éâ' 'éçøa' 'éì' 'éü' 'ê9' 'êk' 'êmìc' 'êp83'\n",
      " 'êr' 'êt' 'êv' 'êå' 'êë' 'êö' 'ëb' 'ëc' 'ëe' 'ëjã0' 'ëm' 'ën' 'ënã0'\n",
      " 'ënã6' 'ëp' 'ëu' 'ëv' 'ëw' 'ëà²' 'ëèq' 'ëõ' 'ëû' 'ëûõêà' 'ëÿ' 'ì8ìû' 'ìb'\n",
      " 'ìm' 'ìq' 'ìv' 'ì½' 'ìç' 'ìê' 'ìòb' 'ìòmë' 'ìô' 'ìú' 'í1' 'í5' 'ía'\n",
      " 'íacðxëó' 'íjã0' 'íqb' 'ís' 'ítswf' 'ítä' 'íx' 'íy' 'íz' 'íà' 'íâ' 'íã'\n",
      " 'íì' 'íõ9mô' 'íõî' 'íöü' 'íû' 'íü' 'îf' 'îqô' 'î²' 'î¾c' 'îâòúj' 'îã'\n",
      " 'îí' 'îî' 'îïæuvãú' 'îö' 'îù' 'îû' 'ï8' 'ïrt' 'ïræ' 'ïy' 'ïßüi' 'ïà' 'ïã'\n",
      " 'ïãn' 'ïòøh' 'ïôc' 'ïúá³' 'ïü' 'ïþb' 'ð2' 'ð8' 'ðaþñãývzhe' 'ðb' 'ðe'\n",
      " 'ðf' 'ðnï' 'ðz' 'ðzs' 'ð³' 'ð¼ñêz' 'ðð' 'ðñ' 'ðóåð7_îµj¾á' 'ðú'\n",
      " 'ðú¼ù¹ávª' 'ðû' 'ðþ' 'ñ8' 'ñb' 'ñoú' 'ñp' 'ñr' 'ñwb' 'ñz' 'ñ½qúá' 'ñ¾'\n",
      " 'ñà' 'ñæ' 'ñé' 'ñëà¾' 'ññ' 'ñú' 'ñú1' 'ò_' 'òav' 'òcå' 'òk' 'òm' 'òraiy'\n",
      " 'òzwb' 'ò¹k' 'òå' 'òêå' 'òñ' 'òø' 'òý' 'òýçdbîp' 'óg' 'óhòj' 'ój' 'óm'\n",
      " 'óq' 'ór' 'ó½5' 'ó½ñõd' 'óãoß' 'óé' 'óê' 'óïó' 'óýnâ' 'óþ' 'ô9' 'ô_' 'ôc'\n",
      " 'ôd' 'ôg' 'ôj5' 'ôu' 'ôw' 'ôx' 'ôµ' 'ô¾ê' 'ôåw' 'ôéw' 'ôí' 'ôîn' 'ôõ'\n",
      " 'ôû' 'ôûëç' 'õe' 'õhü' 'õt' 'õzó' 'õä' 'õå' 'õê' 'õë' 'õì' 'õó' 'õõsm'\n",
      " 'õõxcws' 'õùóa½' 'õûò' 'õý' 'õþbu' 'ö8' 'öi' 'ölsxþ' 'öt' 'öw' 'öx'\n",
      " 'ö³ðçóòf' 'öºõàk' 'öçcrÿ' 'öïî' 'öø' 'öù' 'ød' 'øe' 'øjº' 'øl' 'øy' 'øæ'\n",
      " 'øé' 'øê' 'øí' 'øðò' 'øó' 'øø' 'ù0' 'ù7' 'ùc' 'ùd' 'ùi' 'ùp' 'ùq' 'ùz'\n",
      " 'ùß' 'ùà' 'ùá' 'ùê' 'ùí' 'ùó' 'ùô' 'ùöoæøú' 'ùúô' 'ú0' 'úaë' 'úc' 'úp'\n",
      " 'úq' 'úqa' 'ús' 'úuc' 'úu¹ö' 'úã' 'úé' 'úòbýä' 'úû' 'ûk' 'ûp' 'ûrû8' 'ût'\n",
      " 'û¼x' 'ûñ' 'ûñí' 'ûø' 'ûøj' 'ü0' 'ü_ð' 'üa' 'üdéµ' 'üe' 'üe2²' 'ül' 'üp'\n",
      " 'üq' 'üæe' 'üê' 'üð' 'üù_ê' 'ý5' 'ýb' 'ýcõc' 'ýdrfî½g' 'ýgi' 'ýn' 'ýt'\n",
      " 'ýzõàçô' 'ýçî' 'ýüä' 'þ1' 'þe6x' 'þs' 'þsë' 'þw' 'þz½î' 'þå' 'þúho' 'þû'\n",
      " 'þý' 'þýç' 'ÿáðó' 'ÿêãé' 'ÿþ' 'ÿÿ']\n",
      "[[0.0196703  0.0196703  0.0196703  ... 0.0196703  0.05168007 0.25571386]\n",
      " [0.02049739 0.02049739 0.02049739 ... 0.02049739 0.02692656 0.26646613]\n",
      " [0.0202278  0.0202278  0.0202278  ... 0.0202278  0.02657241 0.26296146]\n",
      " ...\n",
      " [0.01926851 0.01926851 0.01926851 ... 0.01926851 0.02531223 0.23122214]\n",
      " [0.02024983 0.02024983 0.02024983 ... 0.02024983 0.         0.24299793]\n",
      " [0.01830107 0.01830107 0.01830107 ... 0.01830107 0.02404134 0.21961288]]\n"
     ]
    }
   ],
   "source": [
    "#TF-ID\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # top 1000 important words\n",
    "X = vectorizer.fit_transform(df['cleaned'])\n",
    "y = df['label']\n",
    "print(vectorizer.get_feature_names_out()) # Shows unique words\n",
    "print(X.toarray()) # Displays TF-IDF values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Data Analyst       0.00      0.00      0.00       0.0\n",
      " Graphic Designer       0.00      0.00      0.00       1.0\n",
      "Marketing Manager       0.00      0.00      0.00       2.0\n",
      "       Operations       0.00      0.00      0.00       0.0\n",
      "  Product Manager       0.00      0.00      0.00       1.0\n",
      "Software engineer       0.00      0.00      0.00       1.0\n",
      "\n",
      "         accuracy                           0.00       5.0\n",
      "        macro avg       0.00      0.00      0.00       5.0\n",
      "     weighted avg       0.00      0.00      0.00       5.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\panda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\panda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\panda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\panda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\panda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Training the model with resumes in logistic regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Evaluating the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict New Resume\n",
    "def predict_resume(text):\n",
    "    cleaned = preprocess(text)\n",
    "    vector = vectorizer.transform([cleaned])\n",
    "    return model.predict(vector)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the skills you have:\n",
      "Entered Skills: Tableau\n",
      "Predicted Role: Data Analyst\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Give the skills you have:\")  \n",
    "new_resume = input()\n",
    "print(\"Entered Skills:\", new_resume)\n",
    "print(\"Predicted Role:\", predict_resume(new_resume))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
